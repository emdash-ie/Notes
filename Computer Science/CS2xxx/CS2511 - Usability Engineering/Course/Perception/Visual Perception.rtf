{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Visual Perception\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We often think of our visual system as an extremely accurate reproduction of the world around us, but that's not really the case.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The human visual system can be divided into two stages:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab physical reception of light\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab processing and interpretation\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The human visual system has both strengths and weaknesses:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab certain things cannot be seen even when present\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab processing allows images to be constructed from incomplete information\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. negative space\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Structure of the Eye\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Only the fovea provides a lot of detail, right in the centre of our vision. Our peripheral vision is very inaccurate.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The brain covers the blind spot either by guessing at what's there or remembering what's there.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The lens in our eye causes an upside-down image on our retina.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Two types of sensor:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab rods (in the retina)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab high sensitivity to light\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab monochrome\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab low resolution\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab cones (in the fovea)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab limited sensitivity to light\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab colour (red, green, blue)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab high resolution\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 There are around 6 million cones, mostly in the fovea, and about 120 million rods, mostly situated around the periphery.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Visual Field\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Because we can only focus on a very small area at a time, we scan scenes [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We have a good spatial memory that allows us to remember (e.g.) where a particular piece of info is on the screen.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Brightness Perception\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Luminance is a physical property that can be measured.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The luminance of an objects depends on:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab the amount of light falling onto its surface\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab The reflective properties of the surface\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Contrast is related to luminance \u8211- it if the difference in luminance between the brightest and darkest parts of an image.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Perception of brightness is subjective.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The human visual system compensates for bright or dark conditions by:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab varying the iris aperture to regulate the amount of light reaching the retina\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab using the lens to direct the image onto different parts of the retina:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab in bright conditions, light is focused on the fovea, giving high resolution and colour vision\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab in dark conditions, focus is shifted onto the periphery, giving greater sensitivity but reducing resolution and colour perception\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 JND\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We can measure the {\i just noticeable different} under various conditions.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Increasing the brightness:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab improves visual acuity\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab increases perception of flicker (flicker may become obvious even at higher frequencies)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Colour Perception\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The total number of colours (rather than hues, at about 150) we can distinguish is much higher (it's typically estimated at 7,000,000 when accounting for hue, saturation, and brightness).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is because:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Each of the pure hues can be mixed with white in various quantities to produce other colours\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. pink is a different colour to red\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab we refer to the spectral hues as fully-saturated colours\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab when mixed with white, we refer to them as partially-saturated or de-saturated\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab The brightness of hues can be changed as well\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Look up CIE triangles and Maxwell triangles if interested in primary colour systems\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab A 3-primary-colour system doesn't get all colours we can see\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab If we used enough primaries to get all colours we can see, some combinations wouldn't produce a colour we can see\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The RGB approach offers:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab good colour consistency across machines, since the colours chosen are easy to specify and reproduce with accuracy\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab all mixtures of the primaries yield valid colours\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab a wide range of colours, although there are some colours that cannot be created.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Only around 2-3% of the cones in our eyes are sensitive to blue light, so discrimination between different shades of a colour is worse for blue than for other colours \u8211- we can see more shades of green.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The eye is most sensitive to green light.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 About 8% of men and 1% of women have some for of colour-blindness (usually red-green).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Colour-perception is "pre-attentive" \u8211- people with normal colour vision perceive and discriminate colours immediately and without conscious effort.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Distance Perception\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Visual angle alone doesn't determine perceived size, as objects at a distance and up close may have the same visual angle.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab We're good at gauging objects' size\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We also use:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab binocular vision - difference in the image seen by each eye\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab head movement - small changes in viewing position produce changes in view that allow distance to be gauged\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab monocular cues - require only one eye\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab relative size\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab relative clarity\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab relative height\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab [\u8230?]\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab familirity / pattern-matching\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Binocular Vision\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Each eye sees a slightly different scene \u8211- retinal disparity. The closer the object, the greater the disparity.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Convergence\par}
{\pard \ql \f0 \sa180 \li0 \fi0 To view objects at different distances, we adjust our focus (this is convergence).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Feedback from eye muscles tells us how much adjustment has been made and so how far away the object is.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Convergence is very difficult to recreate on a screen because everything is in focus and on the same plane.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Because this cue is absent, we can subconsciously tell that something's wrong, and so it takes more effort to use 3D displays for long periods of time.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Head Movement\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Used to be\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Distance Perception\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Relative size\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab where an image features several objects of similar shape, the tendency is to assume that the smaller objects are further away (unless there's contradictory evidence)\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab relative height\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab where the base of a shape is higher than that of a similar shape, the one with the higher base is assumed to be further away\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab this cue relates to the horizon\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab reduced clarity\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab reduced clarity in some parts of an image implies distance\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab interposition\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab when one object is interpreted as obscuring part of another one, the one which seems to be obscured is assumed to be further away\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab texture gradient\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab texture gradient can be seen as a combination of linear perspective and relative size\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab areas in which particular shapes are densely packed will appear more distant than areas in which similar shapes are less densely packed\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. cobblestones leading away\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab perspective\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab we find it hard to avoid interpreting converging lines as indicating linear perspective\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab depth cue shadow\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab we tend to assume the light source comes from above if we don't see another light source\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab also tend to assume objects are viewed from above and not from below\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab familiarity / pattern-matching\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab when processing visual information, we are primarily seeking to identify objects in the visual field\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab we expect certain objects to be of a particular size, and use this information to help us interpret a scene\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Ames Room Illusion\par}
{\pard \ql \f0 \sa180 \li0 \fi0 What happens when some visual cues suggest a particular interpretation of a scene but others suggest a different interpretation?\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Ames (1946) built a room in which the walls on one side were considerably higher than those on the other side, but were also further from the viewing position. He then placed two people in different parts of the room.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Looking from the right position, it looks like the two people are extremely different in size.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Dist Perc (cont.)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 If some of the visual cues conflict with others, our visual system makes a best guess.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab We'll notice it at some level, meaning we'll get tired faster\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab harder to use these systems\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Pre- and Post-Attentiveness\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Eye-movement and focus typically take around 200ms.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Visual tasks that involve eye movement and focus are said to be post-attentive. Pre-attentive\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Examples\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab pre-attentive:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab simple colour-identification tasks\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. finding an object of a particular colour among a group of coloured objects\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab post-attentive:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab identifying/comparing size, shape, etc.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab task involving a combination of factors, e.g. colour plus size\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Reading\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Research shows:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab People read from a computer screen around 25% more slowly than from printed material. Adults typically read print at around 250 words per minute.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab People scan material on screen more than they do printed material (e.g. read progressively less of each line / paragraph as they move down the screen).\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab People dislike scrolling.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab People dislike wordy text (on computer screens).\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This may be because computer screens and the typography and layout often used on computers [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When children learn to read, they initially read linearly:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab read each word in turn\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab identify the meaning of each word (possibly letter by letter)\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab identify the meaning of each sentence\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is slow and inefficient. As children become more proficient, they learn to scan text by spotting key-words. This process involves a number of stages:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Identify a word or character\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab long words recognised as quickly as single characters\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab shape important here\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab guess the meaning of the phrase or sentence\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab confirm/disprove the guess\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab the reader jumps forward through the text looking for words or characters that will confirm/disprove the guess\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab forward jumps are known as saccades (the eye movement?)\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab revise the guess if necessary\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab if a guess cannot be confirmed, it may be necessary to back-track and revise the guess\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab backward jumps are known as regressions\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We typically read 1 in 4 or 1 in 5 words of what we're reading (fewer for dense materials).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Factors Affecting Legibility\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Font-style and capitalisation\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab pattern-recognition is crucial to reading, so typefaces with distinct patterns are easier to read than other. Block capitals are particularly hard to read (for extended periods).\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Font size\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Font sizes from 9-12 points are equally legible (assuming proportional spacing)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab larger and smaller sizes are less legible\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab line length also important \u8211- want to facilitate saccades rather than forcing people to skip lines\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Character spacing\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab proportionally-spaced text is easier to read than text with fixed-spacing.\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Line length\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab lengths of between\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Text colour\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab [\u8230?]\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Morkes and Nielsen (1997) asked subjects to rate versions of a page \u8211- they created versions which contained the same information but presented/worded it differently.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab abbreviated text \u8211- 58%\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab text split into single lines \u8211- 47% better\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab objective language only \u8211- 27% better\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Combining all three approaches was rated 124% better than the original.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Concluded it's best not to provide too much info at the top level, that way people can choose to see more info that they are specifically interested in.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 2D vs 3D\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Why do we not use 3D?\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab maybe cost\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab good 3D technology is more expensive and less available than 2D\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 But there's also research suggesting that 2D is better for many practical applications.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab cognitive/perceptual effort\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab 3D takes more effort from the viewer than 2D\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab in 3D, some cues may be absent, incomplete, or misleading\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab presenting incomplete/incorrect 3D information increases the cognitive load\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab abstraction vs. realism\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab we are used to seeing abstract 2D views, but expect 3D views to be realistic\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab generalisation\sa180\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab 2D views are better suited to scaling, zooming, etc.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab these may be just because we're used to 2D and may go away once we get used to 3D\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 3D is suited to applications that involve the visualisation of real objects and their orientation/relationship to other objects:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab medical imaging\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab mechanical modelling\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab architectural modelling\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab layout of internal spaces\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab sightlines\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 2D tends to be better suited to applications that involve exploration or visualisation of abstract data, e.g.:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab a computer's file structure\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab financial and commercial data\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 3D displays are increasingly used in visualisation of complex, multi-dimensional data. However, many designers recommend avoiding 3D if alternative 2D representations can be used.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Games break all of these rules \u8211- a game can be very hard to use according to HCI but the motivation from enjoyment of the game is strong enough to overcome it all.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Screen as External Memory\par}
{\pard \ql \f0 \sa180 \li0 \fi0 By presenting a lot of information at once we can use the screen as external memory and reduce the load on the user's short-term memory.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 However, studies suggest that users skim material on webpages, and that it is usually best to minimise the amount of material per page.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 You need to be clear how the material on the screen is to be used:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab for tasks that involve comparison, analysis, decision-making, it is usually best to place as much relevant information on screen.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab for most other purposes, users won't read lengthy passages from a screen, so minimise the amount of text and make it as readable as possible\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Complex Data\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When presenting complex data:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab colour is a good choice of cue because it is perceived pre-attentively\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab but some people are colour-blind, so provide redundancy and/or allow customisation\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab shape and size are perceived post-attentively, but can still be used effectively\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab brightness is a poor cue because humans adapt to it\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab though contrast?\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Text\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When presenting text:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab choose appropriate fonts, font-sizes, etc.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab minimise the amount of text by removing all unnecessary material\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab avoid descriptions\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab break up the text using (e.g.) bullet points\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 If using longer passages of text is unavoidable, try to minimise its complexity. There are a number of methods that can be used to measure the complexity of a passage of text:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab average reading time\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab a group of people are asked to read the text, and the average time taken is noted\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab not easy to do quickly / on a deadline\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Cloze technique\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab subjects are asked to read a piece of text in which every fifth word is blanked out\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab the index is based on the percentage of blanked words that are guessed correctly\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab texts with simple, predictable structures usually obtain high scores\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab still a lab measure (takes time + effort)\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Fog index, Flesch reading ease test, etc.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab take into account factors such as average word and sentence length, percentage of complex words, etc.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab grade texts in various ways:\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab on a scale from 6-17, indicating the age at which pupils should be able to ready text of that complexity\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab on a 100-point scale\sa180\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab very good for US English, not so good for anything else (even Irish English)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab however, it's super quick\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab many word processors have built-in readability tools\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab tools are available online\sa180\sa180\sa180\par}
}
