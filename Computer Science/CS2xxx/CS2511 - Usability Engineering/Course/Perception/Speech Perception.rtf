{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Speech Perception\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Attempts to use speech in computer applications cause slow and inefficient communication.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 But studies show human can communicate very efficiently using speech.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is because human speakers are very careful when choosing:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab what to say at each point in an exchange\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab bear in mind what has already been said\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab also their impressions of the listener\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab how to say it\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab format speech so that important information is highlighted, making it easier for the listener to identify\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Speech is a co-operative activity, in which the speaker seeks to identify and meet the communication needs of the listener, and the listener provides feedback to the speaker to aid in this process.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 It's important to understand how human speech communication works if we are to develop better speech-based computer interfaces. Speech communication also provides a useful model for other forms of human-computer interaction in the era of ubiquitous computers.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Models of Speech Perception\par}
{\pard \ql \f0 \sa180 \li0 \fi0 More recent models assume a top-down approach:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab search speech stream and locate key-words\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab identify the meaning of the key-words, then guess at the meaning\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab if unsuccessful, analyse more words until the meaning has been extracted\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Note:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab top-down models suggest we perceive speech in much the same we read text\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab both types of model assume that speech is held in a temporary store during processing\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab modern models fit well with the concept of humans as lazy processors\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Speech Content\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When speaking, human beings:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab assess what is relevant to the listener at the current point\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab construct a phrase containing this information, taking care to:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab exclude information that is already known to the listeners or that they can infer\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab use as few words as possible without sacrificing clarity\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab present the phrase with appropriate prosody\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab prosody is pitch, volume, pauses, gestures, etc.\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 In deciding what is relevant, an important factor is the distinction between new information and given information.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 New Information & Given Information\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab a typical spoken phrase is constructed around one word\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab this word is deemed by the speaker to contain new information not previously known to the listener or inferable from the context\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab most of the remaining words either:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab complete the grammatical structure\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab or provide redundancy by presenting information already known to the listener or inferable from the context\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab such words are said to contain given information\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Content Words and Function Words\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Some of the words within a phrase are essential, for example verbs and nouns. The phrase cannot be understood if they are omitted or mis-heard. These are {\i content words}.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Other words are not essential. The phrase can be understood even if they are omitted or mis-heard.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Speech Delivery\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When speaking, we provide prosodic cues to help our listeners parse the speech stream. Appropriate prosody helps the listener identify key-words (new information and content words).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Intonation\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab The pitch rises at the start of each phrase and falls at the end.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Where several phrases follow in succession, each has a lower average pitch than its predecessor\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Within each phrase, a sharp change in pitch marks the position of the new information.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Rhythm\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Stressed syllables of key words (new information, content words) are spoken at regular intervals and may also be marked by an increase in volume\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab pauses are placed between words where necessary to support the rhythm\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab longer pauses are placed between phrases\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Non-Speech Cues\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Used to highlight the position of important information within the speech stream.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab gesture\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab facial expression\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Collaboration, Clarification and Repair\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Note we're just talking about speech that's focused on effective communication, e.g. 911 calls.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Successful speech communication relies on the maintenance of a shared context between speaker and listener(s).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 As an exchange proceeds information is shared, and each participant relies on this shared context when formulating contributions.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 In addition, each participant learns more about the other.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 In general HCI using speech has been context-free.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Having a shared context makes it easier to decide how much background knowledge needs to be communicated and what can be excluded in order to keep utterances brief.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Shared Context\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab history of conversation\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab impression of participants\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab knowledge\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab analytical skills\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab memory\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab expectations / boundaries\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab cultural\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab religious\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab other\sa180\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 In an effort to communicated efficiently, we often place too much reliance on this shared context \u8211- we provide incomplete information and hope that listeners will fill in the missing information by reference to the context.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This doesn't always work, with the result that communication breaks down.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Clarification and repair is important \u8211- it's part of what allows speech to be so effective. Forms a rapid feedback loop. This is often absent when speaking with machines.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 If listeners do not understand something, this soon becomes clear to the speaker \u8211- lack of understanding may be signalled by various means:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab facial expression\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab explicit request for clarification\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When this happens the speaker usually responds by re-phrasing or providing more context.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Designing Speech-based Interfaces\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Speech can be used for input (speech recognition) and for output (speech synthesis).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Some systems use speech for both input and output (e.g. voicemail (?)) while others use speech only for output (e.g. SatNav), and a few use speech input in conjunction with visual output.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Speech-based interfaces are being used in an ever-wider range of applications, but while the necessary technology is available, there are generally very few guidelines. [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Speech Recognition\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Recent systems (e.g. Siri) use a brute force match against a large database of stored phrases to determine the meaning of the input utterance.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Speech recognition involves two steps:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab word recognition\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab construction of meaning\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Most of the problems with word recognition have been solved. However, recovering the meaning from a sequence of words is far more difficult. Many problems need to be overcome before computers can handle unprompted speech input (speech that has been stripped down).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Prompted speech is achieved by giving questions in a particular format \u8211- most people will respond in the same/expected format.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Even when the individual words are correctly recognised, speech is more difficult to analyse than written language. Converting speech into text and then using these doesn't work though.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Where you can train a system (e.g. Dragon Dictate), word recognition can be especially good.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 There are number of reasons written language is easier than speech:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab speech has no punctuation \u8211- parsing cues are provided through a mixture of pausing, intonation and stress in ways that are complex and not fully understood\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab they also vary from person to person\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab fragmentary phrases are common\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab we often don't finish sentences because we can see that the sentence has been understood\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab repetition and re-phrases are common\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab partway through a sentence we may think of a better way to phrase it and start again\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab this is easy for humans to understand but difficult for machines to understand\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab speech relies heavily on non-grammatical sentence forms (minor sentences)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab a lot of words are stripped out\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A major (or regular) sentence has the full grammatical form appropriate to its type, e.g. a statement with formal declarative structure.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A minor (or irregular) sentence has an incomplete or abnormal grammatical structure.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Speech makes extensive use of anaphora \u8211- e.g. using he/she/him/her/they/them rather than referring to a person or object by name.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Efficient speech communication relies heavily on other communication channels \u8211-\u160?gesture, facial expression, etc.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Ambiguous words, phrases, etc. are often used in order to achieve brevity, with the correct interpretation being signalled through prosody.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The speech context is dynamic, changing as the exchange progresses. Modelling this context is extremely difficult.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Until quite recently, speech recognition has been mainly used in applications involving:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab speech to text transcription, where recovery of meaning is not necessary\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab tightly-constrained problem domains, where vocabulary can be limited and every word given a fixed meaning\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Recently, the ability to rapidly search large databases of tagged speech samples has enabled more potential applications.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Speech Synthesis\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The design of speech output can be separated into two stages:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 1.\tx360\tab Deciding what should be said and when\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 2.\tx360\tab Choosing appropriate prosody for each utterance\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Some frameworks exist to assist in the design of dialogues, but much work still needs to be done.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Considerable work has been done on creating rules to generate valid prosody, but for best results the output must be hand-tuned.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 To tell where the intonation needs to go, the context is required to spot the keywords in the sentence.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Current TTS (text to speech) systems generate high-quality synthetic speech, but studies show people still have more difficulty using synthetic speech than natural speech:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab people usually understand it as well as natural speech\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab but understanding requires more effort than natural speech\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The comprehensibility of speech can be assessed using a technique devised by Luce (1982):\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Subjects are presented with a passage of speech and asked to recall the way in which it is spoken.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab The more difficult the speech is to understand, the more subjects will recall of the syntax and surface structure\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This suggest that people have to perform more analysis to extract meaning from poor-quality speech.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Here's another approach:\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Comprehension of spoken tracts were compared under four conditions:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab natural speech, meaningful content\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab natural speech, meaningless content\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab synthetic speech, meaningful content\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab synthetic speech, meaningless content\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 They found:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab subjects understood meaningful content\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab word-recognition was better for meaningless content with natural speech\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This all suggests that listeners rely more heavily on context when trying to understand synthetic speech.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A simplified version of the second approach, measuring word-recognition rates for standard passages of meaningless text is widely used for [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Studies show that the gap between natural and synthetic speech has narrowed, but synthetic speech remains far more difficult to understand than natural speech.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is probably because most synthetic speech lacks adequate/appropriate prosody and other cues.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Generally they struggle with new words.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Applications\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A number of standards exist that allow speech synthesis and recognition to be used on webpages:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab voiceXML\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab XHTML + voice\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab SALT (Speech and Language Tags)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Most browsers currently require plug-ins to handle speech, but a few have built-in support (e.g. Opera), and others will soon follow.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Aircraft Maintenance\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Interesting because it's a safety-critical domain. Also a lot of components have to be replace very frequently \u8211-\u160?there's maintenance every time a plane lands.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Several proprietary systems are in use which allow engineers to inspect aircraft and record their comments ("this needs to be replaced, this will soon", etc) through speech, thus leaving their hands free for the task.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The spoken comments are then automatically converted into maintenance schedules, lists of parts to order, etc.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This system is reliable because the vocabulary is precisely defined. Engineers are trained to use only the words in the vocabulary, and to use them only as defined by the system.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The system is {\i completely} reliable.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Voice Mail Systems\par}
{\pard \ql \f0 \sa180 \li0 \fi0 These also rely on a defined vocabulary.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 They normally recognise numbers, along with a set of defined words related to the domain. For example, a company might allow users to locate the nearest branch office by entering the name of a town or city.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Applications Using Speech (cont.)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Screenreaders for blind and visually-impaired users.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Screenreaders convert the visual information on a screen into text, which is then converted into speech (or in some cases, Braille).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Typical features include:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab keyboard shortcuts for operations normally performed using the mouse\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab all text made available through speech/Braille\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab standard icons described using text\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab use of scripts to customise applications\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab scripts difficult to write for an individual user, usually organisations make scripts available for a wide range of popular programs\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab assignment of voices according to role/purpose\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. a male voice for commands, a female voice for content\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab control of voice-selection, speech speed, prosody (by rule), etc.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 One of the major challenges in the design of speech systems is to provide an overview that approximates a visual glance.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A glance allows sighted users to determine:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab how much information is present on a screen\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab how it is organised\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab whether/which parts are worth exploring further\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab an appropriate strategy for exploring the information\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Accessing information without the benefit of a glance is much more difficult and tiring.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Some experimental systems provide automatically-generated summaries of data. Others use spatial sound, etc, to convey metadata.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Another approach is to provide tools that re-order the data in various ways so as to allow the user to gain an overview of the dataset. For example, when a table is used, the information contained in the table structure needs to be conveyed.\par}
}
