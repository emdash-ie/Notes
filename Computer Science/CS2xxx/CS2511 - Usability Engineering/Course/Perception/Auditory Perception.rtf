{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Auditory Perception\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Like the visual system, the human auditory system can be divided into two stages:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab physical reception of sounds\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab processing and interpretation\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Like the visual system, the auditory system has strengths and weaknesses:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab certain things can't be heard even when present\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab processing allows sounds to be constructed from incomplete information\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. the fundamental of a bass instrument\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Sound has pitch, timbre, and loudness.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Pitch\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We talk about JND again with pitch (just noticeable difference). This is pretty constant for pitch but varies for frequency because of the logarithmic scale.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Loudness\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We adapt to loudness, so it's not a good cue.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Human beings are very poor at judging the loudness of sounds that are heard for less than 0.2 seconds. These sounds seem much quieter than they are.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Perceived loudness varies with frequency (strongest in the centre).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Timbre\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The timbre of a sound is determined by the relative level of its harmonics and by its amplitude envelope (the way in which the amplitude varies over the time). The envelope helps us distinguish between instruments with similar harmonic content.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Localisation of Sound Sources\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Stereo hearing allows us to locate the source of a sound by comparing the sound at each ear\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab we compare amplitude between each ear (interaural intensity)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab also compare time of arrival (interaural delay)\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab we can recognise differences of 10 microseconds or less between the time of arrival of a sound at each ear\sa180\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab stereo hearing works in the horizontal plane only and is least effective in the middle range of audible frequencies\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Head movement allows us to improve the localisation accuracy of stereo hearing\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab localisation accuracy better for non-musical sounds\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab localisation best straight ahead and straight behind\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab front-back reversals happen but are less common for clicks and noises\sa180\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab localisation varies with frequency\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab good below 1000 Hz, based on timing/phase differences\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab poor between 1000 and 3000 Hz\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab good above 3000 Hz, based on intensity differences\sa180\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Analysis of reflected versus direct sound yield information about the route a sound has travelled to reach us.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Familiarity / pattern-matching affects localisation accuracy \u8211-\u160?both ways\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. we see a ventriloquist's dummy's mouth move and assume the sound is comping from there\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Vertical Localisation\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Research has shown the the average listener can reliably distinguish only three vertical source locations.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Distance\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Judgment of distance is based partly on intensity \u8211- the quieter the sound, the further away the source.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Distance also affects:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab The audio spectrum of the sound \u8211-\u160?some frequencies travel better than others\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab bass frequencies don't travel very well\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab The balance between reflected and direct sound \u8211- the further the sound has travelled, the more likely it is to include a significant percentage of reflected components\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Head-Related Transfer Functions\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Sound localisation can be improved by tailoring the sound distribution.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Ideally, HRFTs should be tailored to suit the individual. However, this is complex and costly.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Researchers are currently trying to develop non-individualised HRTFs which will give a useful improvement in localisation accuracy for a substantial percentage of the population.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Sensory memory for Audio\par}
{\pard \ql \f0 \sa180 \li0 \fi0 As with other senses, it appears that there is a sensory memory associated with the hearing system \u8211- the echoic memory.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 It stores the last few seconds of incoming sound, in its raw form. There's disagreement as to how long the store is, but studies agree that there's a store.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 speech and Non-Speech Sound\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Research suggests that the human hearing system responds differently to speech than to other sound.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Summary\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Human beings are good at:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Detecting changes in pitch, and distinguishing between differing successive pitches\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab recognising and distinguishing between rhythmic structures\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab recognising and distinguishing between familiar timbres\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab localising the source of low-pitched and high-pitched sounds in the horizontal plane\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We're bad at:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab recognising absolute pitches, or distinguishing between different pitches presented at significantly different times\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab detecting changes in loudness (unless the changes are huge)\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab recognising and distinguishing between unfamiliar timbres\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab localising the source of mid-pitched sounds in the horizontal plane\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab localising the source of all sounds in the vertical plane\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Applications\par}
{\pard \ql \f0 \sa180 \li0 \fi0 In mainstream computing, sound is rarely used as a primary means to communicate information.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 It is used mainly for:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab simple warnings (success, failure, etc.)\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab to make educational applications more engaging\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab in entertainment [\u8230?]\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Sound is used more extensively in a number of specialised fields, including:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab applications for blind and visually-impaired people\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab hands-free/eyes-free applications\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Sound has been used in interfaces in a number of ways. Synthetic speech is easy to use, and its meaning is immediately obvious.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 But speech is a relatively slow method of presenting information and places a heavy load on cognitive resources.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Two different approaches have been developed:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Auditory icons are based on natural sounds, and are intended to be instantly recognisable to the user.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab However, it can be difficult to find appropriate sounds to represent many functions.\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Earcons are musical motifs, etc., which are structured so as to convey information. This overcomes the problem of associating sounds with functions, but the user has to learn the meanings of the earcons in each application.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. a particular rhythm means one thing, a particular timbre means another thing\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A newer idea is speech-earcons (Spearcons):\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Spearcons use speech which has been speeded-up until it is only just recognisable.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab users can initially identify the meaning of a spearcon by listening carefully to the speech\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab however, as they learn the meaning of each spearcon, they can ignore the speech content and treat it as non-speech sound\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab this involves much less cognitive effort.\sa180\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Applications\par}
{\pard \ql \f0 \sa180 \li0 \fi0 TIDE Maths projects used sound to help blind people work with mathematical equations:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab 3D sound projection was used to place each term of a polynomial expression at a unique position in space\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab To avoid overloading the user with sounds, each expression had a characteristic 'background' sound which it made when not selected\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. the same sound but muffled/mumbled\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab When selected, the term would be spoken out, with non-speech sound used to indicate parentheses, grouping, etc.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab e.g. tone for each parenthesis and a continuous tone inside the pair\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Placing things in 3D space allowed users to employ spatial memory rather than relying solely on short-term memory.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 In one implementation, the terms could be manipulated using a data glove. This further improved performance, perhaps because it allowed use of both spatial and haptic/kinaesthetic memory.\par}
}
