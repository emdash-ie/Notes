{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Intro\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Might use guidelines in the early stages, whereas heuristics and metrics assume you have some design already done, even if it's just a basic prototype.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Both approaches involve analysing a prototype to see how usable it is.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Heuristics\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab techniques based on experience that help in problem solving\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab tend to be quick and rough \u8211- a means of arriving at a 'good enough' solution\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab rules of thumb, educated guesses, intuitive judgments, common sense\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Approach\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A number of evaluators examine an interface and assess its compliance with a set of recognised usability principles (the heuristics).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Heuristics are general rules (usually around 10 of them are used) which describe common properties of usable interfaces.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Similar to guidelines but framed to be used in an analytical rather than generate manner (assessing existing things rather than creating new things).\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab each evaluator is asked to assess the interface in the light of the heuristics\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab each evaluator should work through the interface several times\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab evaluators should either write down their comments or verbalise them, so they can be recorded or noted by an observer\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab if an evaluator encounters problems with the interface the experimenter should offer assistance, but not until the evaluator has assessed and commented upon the problem\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab don't offer assistance immediately, so that you can see how bad the problem is\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Evaluators work alone so they can't influence one another. Only when all the evaluators have assessed the system individually should the results be aggregated and the evaluators allowed to communicate with one another.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This communication may be useful at this point.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The number of evaluators is typically between 3 and 10, and they should have no prior knowledge of the interface or of the goals of the project.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Using a single evaluator - even an experienced one - may not identify all the usability problems in an interface because different people identify different problems.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Nielsen (1992) conducted a study:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab 19 evaluators were asked to assess an interface against a set of heuristics\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab between them they identified 16 usability problems\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab some evaluators identified a far higher percentage of problems than others\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab some problems were only identified by one or two evaluators, who were not necessarily the evaluators who found a higher percentage of problems\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Using a large number of evaluators increases the likelihood of identifying problems but may also increase costs.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Nielsen concluded that four evaluators is the best compromise between cost and effectiveness.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Metrics\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab more expensive\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab more time-consuming\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab more reliable\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab give quantitative results\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab can compare, e.g. "this one got 80% and the other got 75%, so let's go with the first"\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab distinguish from Usability Testing, where we're comparing (e.g.) two products from two companies\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab here we're testing against a known standard embedded in the rules\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Techniques\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Usually involve asking a group of users to perform a specified task (or set of tasks).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The data gathered may include:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab success rate (task completion/non-completion, % of task completed)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab time\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab errors (number of errors, time wasted by errors)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab use of help/documentation (number of instances, time spent)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab failed commands (number, how often repeated)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab user satisfaction (a subjective measure)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Once gathered, the data may be presented in a number of ways:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab aggregated to yield either a set of scores, each reflecting a different aspect of usability, or a single overall usability rating\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab analysed statistically to yield values that can be expressed to known level of uncertainty\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Examples\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Cognitive Walkthrough\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Doesn't really belong in either category, but is often grouped with metrics\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab aims to evaluate the steps required to complete a task and identify mismatches between the way the user thinks about the task and the way the designer thinks about the task\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Involves the following stages:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab user selects a task to be performed\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab user writes down all the steps required to complete the task\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab for each action in the task, the user:\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab explores the prototype, notes, available information\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab selects the action that appears to match the required action most closely\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab interprets the system's responses and assesses if any progress has been made towards completing the task\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 As the user is doing this, evaluators attempt to answer the following questions for each step:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab how does the user know what to do next?\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab can the user connect the description of an action with what they are trying to do?\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab can the user tell if they have made the right choice on the basis of the feedback supplied by the system?\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?SUMI (Software Usability Measurement Inventory)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A number of subjects are asked to use a system and then complete a questionnaire about it. At least 12 subjects are required, preferably far more.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is quite expensive, and usually happens late in the process, not as early as heuristics.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The questionnaire typically contains 50 questions, of which the following are examples:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab This software responds too slowly to inputs\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab the instructions and prompts are helpful\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab the way that system information is presented is clear and understandable\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab I would not like to use this software every day\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Questionnaires are machine-assessed \u8211- can notice if people contradict themselves, assign a weighting to answers where people were paying attention / thinking about the questions.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Note the mix of positive and negative questions. People will too easily fall into the pattern of (e.g.) deciding they like the product and so not really reading the specific questions, just selecting the positive responses.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab 50 questions is a lot of questions\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab people will follow a large question if they're paid\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Results\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The results are analysed to give scores on the following scales:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab efficiency\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab affect\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab helpfulness\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab control\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab learnability\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The designers of SUMI claim that it has a high level of reliability.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Reliability is measured by asking several different groups of subjects to fill in questionnaires for the same system. If the scores for each group are similar, it can be assumed that the questionnaire is revealing information about the system, not the subjects.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 \u160?Automated Testing\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Since webpages follow an open-source standard, it's possible to test some of their features automatically.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Some automated testers only check the validity of the code, but others test for conformance with usability and accessibility guidelines.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Examples:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab paid-for services such as IBM's Rational Policy Tester Accessibility Edition\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab free, online checkers such as:\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab WAVE (http://wave.webaim.org)\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab possibly more sophisticated than the other free examples\sa180\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab TotalValidator (http://www.totalvalidator.com)\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab Cynthia Says (http://www.cynthiasays.com)\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab quite popular\sa180\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 They automatically check many of the accessibility issues listed in the WCAG, e.g.:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab inclusion of alt text, summaries, table header information, etc.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab contrast between foreground and background colours\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Where a page is found to violate the guidelines, most testers identify the type of error and the line of html code on which it occurs.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Many accessibility issues cannot be checked automatically, so testers usually issue a number of warnings for things to check manually.\par}
}
