{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Exploiting Memory Hierarchy: Main Memory, Associative Cache\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Write Allocation\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [missed the start of this]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A write miss is when the processor wants to write data into memory that isn't there(?).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The memory needs to be fetched into a buffer and then overwritten.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 An alternative is write-around \u8211- don't fetch the block, just write into the main memory. (no writing in the cache?)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 For write-back:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab usually fetch the block\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab use write buffer to avoid overwrite\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab write to the buffer, check if consistent, then write to main memory if it is\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Example: Intrinsity FastMATH\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab embedded MIPS processor\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab 12-stage pipeline\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab uses one part of cache for instruction fetch and one part for data, which can operate in parallel\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab called a split cache strategy\sa180\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The miss rate is much lower for the instruction cache (because it's mostly reading?).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Main Memory Supporting Caches\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Use DRAMs for main memory:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab fixed width (e.g. 1 word)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab connected by fixed-width clocked bus\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab bus clock is typically slower than CPU clock\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Performance Summary\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When CPU performance is increased, the miss penalty becomes more significant.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When the clock rate is increased, memory stalls account for more CPU cycles (because the CPU cannot progress unless the data is brought in).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Can't neglect cache behaviour when evaluating system performance.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Associative Caches\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Fully associative \u8211- allow a given block to go in any cache entry. (place in next available spot)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This requires all entries to be searched at once. (the cache has to be searched for the memory address passed down from the CPU)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Also requires a comparator per entry, which is expensive.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab placing data is simple but comparing it is expensive\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 N-way Set Associative\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab middle ground between fully associative and direct map\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Each set contains n entries. Block number determines which set. (block number modulo {\f1 n})\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Search all entries in a given set at once.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Requires n comparators (less expensive than fully associative).\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab can view direct map as 1-way set associative\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Associativity Example\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab With the direct map, everything's a miss because 0 and 8 keep replacing each other.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab With 2-way set associative, the 6 replaces the 8 because the 8 is least recently used.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab With fully associative, we get the maximum number of hits.\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab however, it's slower to access because we have to search the whole thing\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab also, we need the extra hardware\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 So we want to increase associativity to decrease the miss rate, but only up to a point. The improvement from increasing associativity decreases as you go.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Replacement Policy\par}
{\pard \ql \f0 \sa180 \li0 \fi0 For direct map, there's no choice.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 For set associative, prefer a non-valid entry. If there isn't one, choose among entries in the set.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Can also use least-recently used, which is simple for 2-way, manageable for 4-way, and too hard after that.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 For more sets, random replacement works well.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Multilevel Caches\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Primary cache (L1) is attached to the CPU and is fast but small.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 L2 cache services misses from this \u8211- it's bigger but slower.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Main memory services misses from L2.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Some high end systems have an extra L3 as well.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Adding more caches means searching is more complicated \u8211- have to perform the search at every level (in the worst case).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Goals:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab reduce cache miss penalty\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab close gap between fast CPU clock rate and long access time for DRAM\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 L1 vs L2\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Primary cache:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab focus on minimal hit time\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 L2 cache:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab focus on low miss rate to avoid main memory access\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab hit time has less overall impact\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Interactions with Advanced CPUs\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Out-of-order CPUs can execute instructions during cache miss:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab pending store stays in load/store unit\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab dependent instructions wait in reservation stations\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab independent instructions continue\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Now the effect of a miss depends on program data flow. This is much harder to analyse, so we use system simulation.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Memory System Dependability\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab How much you can depend on a memory system\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Three things we can do with faults:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab avoid them\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab tolerate them\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab predict them (fault forecasting)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Faults can be intermittent or permanent.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Dependability Measures\par}
{\pard \ql \f0 \sa180 \li0 \fi0 You can measure reliability using the mean time to failure (MTTF).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 You can measure the service interruption using the mean time to repair (MTTR).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Combining these gives the mean time between failures:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab MTBF = MTTF + MTTR\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We can define availability based on this:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Availability = MTTF / (MTTF + MTTR)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We can improve the availability by:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab increasing MTTF\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab fault avoidance, fault tolerance, fault forecasting\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab reducing MTTR\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab improved tools and processes for diagnosis and repair\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 The Hamming Single Error Correction (SEC) Code\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is a redundancy scheme for memory. It implements fault tolerance.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The Hamming distance is the number of bits that are different between two bit patterns.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [check]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Encoding SEC\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab there's a full example in the book\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 To calculate Hamming Error Correction Code:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab number the bits from the left, starting at 1\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab all bit positions that are a power of 2 are parity bits\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab all other bit positions are used for data bits\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Then each parity bit checks certain data bits:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab p1 checks all numbers whose binary representation has a 1 at the end\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab so 1, 3, 5, 7, \u8230?\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab p2 checks all numbers whose binary representation has a 1 in the second-last place\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab so 2, 3, 6, 7, \u8230?\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab p3 checks all numbers whose binary representation has a 1 in the third-last place\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab so 4-7, 12-16, \u8230?\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab etc. (laid out like a truth table)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 To fit a word of size 2^n, you need n+1 parity bits.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 * so 4 parity bits to represent 8 bits, meaning 12 bits total space\par}
{\pard \ql \f0 \sa180 \li0 \fi0 To determine the value of a parity bit, count the number of 1s in the data bits it covers. If it's odd, set the parity bit to 1, if it's even, set it to 0.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Virtual Machine\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab host computer emulates guest operating system and machine resources\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab improved isolation of multiple guests\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab avoids security and reliability problems\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab aids sharing of resources\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Virtualisation has some performance impact, and so is only feasible with modern high-performance computers.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Virtual Machine Monitor (aka Hypervisor)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is the heart of the virtual machine technology.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 It maps virtual resources to physical resources (memory, I/O devices, CPU).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Guest code runs on native machine in user mode.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab traps to VMM on privileged instructions and access to protected resources\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Guest OS may be different from host OS.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [more here]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Instruction Set Support\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab user and system processor modes\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Privileged instructions are only available in system mode \u8211-\u160?trap to system if executed in user mode.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 All physical resources are only accessible using privileged instructions (e.g. page tables, interrupt controls, I/O registers).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Current ISAs are adapting to virtualisation (as it wasn't prominent when they were created).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Virtual Memory\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Use main memory as a cache for disk storage.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab managed jointly by CPU hardware and the OS\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Programs share main memory.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab each gets a private virtual address space holding its frequently used code and data\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab protected from other programs\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The CPU and the OS translate virtual addresses to physical addresses.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab virtual memory blocks are called pages\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab virtual memory translation miss is called a page fault\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab requires going to the hard disk to load the block into virtual memory\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Address Translation\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab virtual memory space can have more addresses than the physical address space\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab discrepancy handled by translation\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Page Fault Penalty\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Page fault penalty for going to the disk is very high.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Try to minimise the page fault rate:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab fully associative placement\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab no pages are in contention (until you run out of space?)\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab search time is high\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab smart replacement algorithms used by the operating system to track placement\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 \u160?Page Tables\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab attempt to make up for high search time from fully associative placement\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab stores placement information\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab array of page table entries, indexed by virtual page number\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab page table register in CPU points to page table in physical memory\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab If page is present in memory\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab page table entry stores the physical page number\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab also other status bits (referenced, dirty, etc.)\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab if a page is not present\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab page table entry can refer to location in swap space on disk\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Swap space: partition on hard drives in linux \u8211- faster to access than the rest of the drive.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Translation Using a Page Table\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Valid bit marks whether the page is in physical memory or on the disk.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Two virtual addresses can point to the same physical address (e.g. when two programs are sharing the same data).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Replacement and Writes\par}
{\pard \ql \f0 \sa180 \li0 \fi0 To reduce the page fault rate, prefer least-recently used replacement.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab reference bit in page table set to 1 on access to page\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab periodically cleared to 0 by the OS\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab a page with reference bit = 0 has not been used recently\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A disk write takes millions of cycles. So:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab write a whole block at once, rather than individual locations\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab write through is impractical\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab use write-back when replacing a page\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab dirty bit in page table set when a page is written\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab a modified page is often called a dirty page\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Fast Translation Using a TLB (Translation Look-aside Buffer)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Address translation would appear to require extra memory references.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab one to access the page table entry\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab then the actual memory access\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 But access to page tables has good locality.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab so use a fast cache of page table entries within the CPU\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab called TLB\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab typically 16-512 PTEs, 0.5-1 cycle for a hit, 10-100 cycles for miss, 0.01%-1% miss rate\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab misses could be handled by hardware or software\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab have to copy the valid, dirty, and reference bits from the page table\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 TLB Misses\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Occurs when no entry in TLB matches a virtual address.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 If the page is in memory, load the PTE from memory and try.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab could be handled in hardware\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab this gets complex for more complicated page table structures\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab or in software\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab raise a special exception, with optimised handler\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 If the page is not in memory (page fault):\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab OS handles fetching the page and updating the page table\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab then restart the faulting instruction\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 \u160?Page Fault Handler\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 1.\tx360\tab Use faulting virtual address to find PTE.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 2.\tx360\tab Locate page on disk.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 3.\tx360\tab Choose page to replace.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab if dirty, write to disk first\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 4.\tx360\tab Read page into memory and update page table.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 5.\tx360\tab Make process runnable again.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab restart from faulting instruction\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Example: TLB and Cache Interaction in FastMATH\par}
{\pard \ql \f0 \sa180 \li0 \fi0 If the cache tag uses physical address:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab need to translate (from virtual to physical) before cache lookup\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 If the cache tag uses virtual addresses:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab complications due to aliasing\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab different virtual addresses for shared physical address\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Memory Protection\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Different tasks can share parts of their virtual address spaces.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab but need to protect against errant access\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab requires OS assistance\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Hardware support for OS protection:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab privileged supervisor mode (aka kernel mode)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab privileged instructions\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab page tables and other state information only accessible in supervisor mode\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab system call exception (e.g. syscall in MIPS)\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Common Framework for Memory Hierarchy\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Common principles apply at all levels of the memory hierarchy.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab based on notions of caching\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 At each level in the hierarchy, the following are relevant:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab block placement\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab finding a block\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab replacement on a miss\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab write policy\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Block Placement\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Determined by associativity.\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab direct-mapped (1-way associative)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab only one choice for placement\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab n-way set associative\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab n choices within a set\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab fully associative\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab any location\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Higher associativity reduces miss rate.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab increases complexity, cost, and access time\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Finding a Block\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Hardware caches:\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab reduce the number of comparisons to reduce the cost.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Virtual memory:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab full lookup table make full associativity feasible\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab benefit in reduced miss rate\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Replacement\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Choice of entry to replace on a miss:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab LRU\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab complex and costly hardware for high associativity\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab random\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab close to LRU, easier to implement\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 [\u8230?]\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Write Policy\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Write-through\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab update both upper and lower levels\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab simplifies replacement, but may require write buffer\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Write-back\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab update upper level only\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab update lower level when block is replaced\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab need to keep more state\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Virtual memory\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab only write-back is feasible, given disk write latency\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Sources of Misses\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Compulsory misses (aka cold start misses)\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab first access to a block that has never been in cache\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Capacity misses\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab due to finite cache size\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab a replaced block is later accessed again\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Conflict misses (aka collision misses)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab in a non-fully-associative cache\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab due to competition for entries in a set\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab would not occur in a fully associative cache of the same total size\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Cache Design Tradeoffs\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab increase cache size\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab decreases capacity misses\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab may increase access time\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab increase associativity\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab decrease conflict misses\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab may increase access time\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab increase block size\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab decreases compulsory misses\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab increases miss penalty (have to swap out the whole block)\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab for very large block size, may increase miss rate due to pollution\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Finite State Machines\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Note: important to know how the tag and index are converted to the address for checking if you have a cache hit \u8211- important for exams.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Cache Controller FSM\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab some optimisations are possible\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Cache Coherence Problem\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab suppose two CPU cores share a physical address space\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab write-through caches\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The memory view of the processors is based on their individual caches.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Each core has its own cache, but since both get their data from memory, how do we keep data in both coherent?\par}
{\pard \ql \f0 \sa180 \li0 \fi0 One core might write a value, and write-through will update that data in memory. This value might now be incorrect in the other core's cache.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Coherence Defined\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab reads return the most recently written value\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab if P writes X and then reads X, the read should return the written value\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab if P1 writes X and then P2 reads X, the read should also return the written value\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab if P1 writes X and then P2 writes X, all processors should see the writes in the same order\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab then the final value of X will be consistent\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 \u160?Cache Coherence Protocols\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab cache in multiprocessors supports\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab migration of data to local caches (reduces bandwidth for shared memory)\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab replication of read-shared data (reduces contention for access)\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab contention in main memory is part of why it's slow\u160?\u8211- cache prevents this\sa180\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Operations performed by caches in multiprocessors to ensure coherence\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 * known as cache coherence protocol\line
\line
* the key part is state tracking of shared data\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Snooping Protocols\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Each cache monitors bus reads/writes\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab sharing status of blocks copied to different caches\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Invalidating Snooping Protocols\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab processor gets exclusive access to a block when it is to be written\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab broadcasts an invalidate message on the bus\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab subsequent read in another cache misses\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab owning cache supplies updated value\sa180\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Memory Consistency\par}
{\pard \ql \f0 \sa180 \li0 \fi0 When are writes seen by other processors?\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab "seen" means a read returns the written value\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab can't be instantaneous\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Assumptions:\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab a write completes only when all processors have seen it\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab a processor does not reorder writes with other accesses\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab so any processor that sees a write must have seen all previous writes\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Supporting Multiple Issue (ARM and Intel i7)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab Both have multi-banked caches that allow multiple accesses per cycle (assuming no back conflicts)\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab core i7 optimisation\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab return requested word first\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab non-blocking cache for out-of-order processors\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab hit under miss: hides miss latency\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab miss under miss: overlaps miss latency\sa180\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab data pre-fetching\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab looks at pattern of data misses\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab predicts next address to start fetching data before a miss occurs\sa180\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Pitfall\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab byte vs. word addressing\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab need to be clear on this\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab example: 32-byte direct-mapped cache, 4-byte blocks\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab byte 36 maps to block 1 (since 9 (= 36 / 4) modulo 8 (= 32 / 4) = 1)\par}
{\pard \ql \f0 \sa180 \li1080 \fi-360 \bullet \tx360\tab word 36 maps to block 4 (since 36 modulo 8 = 4)\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab ignoring memory system effects when writing or generating code\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab example: iterating over rows vs. columns of arrays\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab large strides result in poor locality\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab can drastically reduce performance\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab in multiprocessor with shared L2 or L3 cache\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab less associativity than cores results in conflict misses\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab more cores -> need to increase associativity\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab using AMAT (average memory access time) to evaluate performance of out-of-order processors\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab ignores effect of non-blocking accesses (being able to do other things while waiting for memory)\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab instead, evaluate performance by simulation\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab implementing a VMM on an ISA not designed for virtualisation\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab e.g. non-privileged instructions accessing hardware resources\par}
{\pard \ql \f0 \sa180 \li720 \fi-360 \endash \tx360\tab either extend the ISA or require the guest OS not to use problematic instructions\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Conclusion\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab principle of locality is important\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab fast memory is small, large memory is slow\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab caching gives the illusion of fast, large memory\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab memory hierarchy\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab L1 <-> L2 <-> \u8230? <-> DRAM <-> disk\sa180\par}
{\pard \ql \f0 \sa180 \li360 \fi-360 \bullet \tx360\tab memory system design is critical for multiprocessors\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab processors are very fast, but memory is slow \u8211- good design helps get good performance out of the CPU\sa180\sa180\par}
}
