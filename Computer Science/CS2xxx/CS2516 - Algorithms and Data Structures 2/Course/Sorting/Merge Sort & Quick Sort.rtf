{\rtf1\ansi\deff0{\fonttbl{\f0 \fswiss Helvetica;}{\f1 Courier;}}
{\colortbl;\red255\green0\blue0;\red0\green0\blue255;}
\widowctrl\hyphauto

{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Merge Sort\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Heap sort had complexity O(n log n) and sorted in-place. Is it work looking at more sorting algorithms?\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Are there algorithms with better worst case complexities?\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Even with the same complexity, maybe the lower order terms are better?\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Are there algorithms with better average complexity?\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Is it worth it using in-place sorting?\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Are there other problem-solving strategies we could look at?\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Divide and Conquer\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This is a general problem solving strategy used throughout computing.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab If a problem is simple, solve it in a single step\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab If a problem is too complex to solve in a single step:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Divide it into multiple pieces\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Solve the individual pieces\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Combine the pieces to get a solution\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Typically this is implemented using multiple recursion.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs28 Sorting\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab If an input list is of size 1 or 0, do nothing\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Otherwise:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Split it into two almost equal sublists\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Sort the first sublist\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Sort the second sublist\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Merge the two sublists into a combined list\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 All the work is done in the merging.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs24 Merging\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Say you have two sorted lists of size 4 to be merged into a sorted list of size 8.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Point at the first two elements\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Put the smaller into the new list and move its pointer forward\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Look at the two elements you're now pointing at\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Put the smaller into the new list and move its pointer forward\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Repeat until finished\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Complexity\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Merge sort is O(n log n), which is the same as heap sort. It's also O(n log n) in space complexity.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Alternative Analysis: Recurrence Equations\par}
{\pard \ql \f0 \sa180 \li0 \fi0 The base case is O(1). Merge is O(n), so we will write it as {\f1 c*n}.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Time to sort a list of length n ({\f1 t(n)}) for n > 1, is then:\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 t(n) = 2*t(n/2) + c*n\par}
{\pard \ql \f0 \sa180 \li0 \fi0 But {\f1 t(n/2)} must then be 2{\i t(n/4) + C}n/2, so we can plug it in recursively.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 So t(n) = {\f1 2^k * t(n/(2^k)) + kc*n}.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This eventually stops when the list is of size 1, which happens when k = log_2(n). But t(n/(2^k)) = t(n/(2^log_2(n))) = O(1) since list is length 1.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 So {\f1 t(n) = n + log_2(n)*c*n which is O(n log n)}\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This kind of analysis is needed for some algorithms.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Alternative Merge Sort Implementations\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 1.\tx360\tab Implementing merge sort on linked lists is probably easier.\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Don't have to create new lists.\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 2.\tx360\tab Merge Sort on arrays can be implemented bottom-up rather than top-down, using just O(n) extra space:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Create a new empty list of size n, called list 2\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab For each pair of cells in the original list\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab Merge into sorted pair in corresponding cells in list 2\sa180\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab For each successive group of 4 cells in list 2\par}
{\pard \ql \f0 \sa0 \li1080 \fi-360 \bullet \tx360\tab Merge into sorted group of 4 in corresponding cells in original list\sa180\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab Repeat\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs36 Quick Sort\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Worst-case complexity is worse than the last couple we've looked at, but on average it's much quicker.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 With merge sort all the work was done in the combination \u8211-\u160?dividing was easy. What if we put all the work into clever dividing, and let combining fall into place?\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Think of building a binary search tree from a list, and then doing an in-order traversal to create the sorted list.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab building the tree:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab best case is O(n log n)\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab worst case is O(n^2)\sa180\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab traversing the final tree:\par}
{\pard \ql \f0 \sa0 \li720 \fi-360 \endash \tx360\tab O(n)\sa180\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Procedure:\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 make the first element of the list the root of a tree\line
for all elements in the list\line
    if they are less than root\line
        put them in a left list\line
    else\line
        put them in a right list\line
    if the left list is not empty\line
        build the root's left sub tree from it\line
    if the right list is not empty\line
        build the root's right sub tree from it\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Quick sort applies this procedure but without actually building the tree.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Procedure for doubly-linked lists:\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 quicksort(start, end):\line
    if start.next != end and start != end:\line
        pivot = start\line
        node = pivot.next\line
        while node is not the end\line
            nextnode = node.next\line
            if node.elt < pivot.elt\line
                move node in front of pivot\line
                if first move\line
                    start = node\line
            node = nextnode\line
        quicksort(start, pivot)\line
        quicksort(pivot.next, end)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Array-based Lists\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We want to be able to do it on arrays, in-place. We need to avoid shuffling elements along the array.\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab When dividing, search from both ends, and swap positions of any elements that are on the wrong side of where the pivot will go.\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \f1 sort(list, pivot, end):\line
    while searches not crossed\line
        search right from pivot for a bigger item\line
        search left from end for a smaller item\line
        if searches not crossed\line
            swap items\line
    swap pivot with small item\line
    sort(list, small, pivot)\line
    sort(list, pivot+1, end)\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Analysis\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab Each level of the tree takes at most n comparisons, and at most n/2 swaps\par}
{\pard \ql \f0 \sa0 \li360 \fi-360 \bullet \tx360\tab If the input list is sorted, then worst case depth of the tree is n, [\u8230?]\sa180\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Median Pivot\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We know a balanced tree has depth log n, when each node has equal numbers of descendants on the left and the right. So if we could choose a pivot each time that splits its sublist into two equal parts, our quicksort tree would also be log n depth, and the runtime would be O(n log n).\par}
{\pard \ql \f0 \sa180 \li0 \fi0 We need to pick the median as the pivot every time.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 There's an algorithm ("median of medians") to find the median of an unsorted list in time O(n), but it's complicated. You could run that first and in theory that'll give quicksort a worse-case bound of O(n log n). In practice, though, it's very slow, as the terms in the quadratic for "median of medians" are huge.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 \b \fs32 Random Pivot\par}
{\pard \ql \f0 \sa180 \li0 \fi0 Choosing a random pivot will destroy the bias from getting a sorted or near-sorted list.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 It can be shown that the {\i expected} running time for a random pivot selection is O(n log n). The worst case is still O(n^2), since it's still possible the randomness won't help in certain cases, but it's much less likely.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 A simpler solution is to create a random shuffle of the top level list, and then call the existing algorithm.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 This adds {\f1 n} calls to {\f1 randint} and {\f1 n} swaps. This doesn't change the expected runtime or the worst-case bound.\par}
{\pard \ql \f0 \sa180 \li0 \fi0 In practice, quicksort is still faster than merge sort or heap sort with the random shuffle most of the time.\par}
}
